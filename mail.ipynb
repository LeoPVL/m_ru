{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mail.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5SFM-c8VXGW"
      },
      "source": [
        "import random\n",
        "import string\n",
        "import os  \n",
        "def create_text_file(count,max_len,file_path):\n",
        "  population = string.ascii_lowercase+'1234567890'\n",
        "  with open(file_path,'w') as f:\n",
        "    for _ in range(count):\n",
        "      f.writelines(''.join(random.choices(population,k=random.randrange(0,max_len)))+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_ZEt4g9G85V"
      },
      "source": [
        "def shell_sort(data):\n",
        "    data = list(data)\n",
        "    last_index = len(data) - 1\n",
        "    step = len(data)//2\n",
        "    while step > 0:\n",
        "        for i in range(step, last_index + 1, 1):\n",
        "            j = i\n",
        "            delta = j - step\n",
        "            while delta >= 0 and data[delta] > data[j]:\n",
        "              data[delta], data[j] = data[j], data[delta]\n",
        "              j = delta\n",
        "              delta = j - step\n",
        "        step //= 2\n",
        "    return ''.join(data)\n",
        "\n",
        "def heapify(arr, n, i):\n",
        "    largest = i \n",
        "    l = 2 * i + 1   \n",
        "    r = 2 * i + 2   \n",
        "\n",
        "    if l < n and arr[i] < arr[l]:\n",
        "        largest = l\n",
        "\n",
        "    if r < n and arr[largest] < arr[r]:\n",
        "        largest = r\n",
        "\n",
        "    if largest != i:\n",
        "        arr[i],arr[largest] = arr[largest],arr[i] \n",
        "\n",
        "        heapify(arr, n, largest)\n",
        "\n",
        "def heapSort(arr):\n",
        "    n = len(arr)\n",
        "\n",
        "    for i in range(n, -1, -1):\n",
        "        heapify(arr, n, i)\n",
        "\n",
        "    for i in range(n-1, 0, -1):\n",
        "        arr[i], arr[0] = arr[0], arr[i] \n",
        "        heapify(arr, i, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anq5xNW7eCjs"
      },
      "source": [
        "def sort_and_write_little_file(lines,file_path,files):\n",
        "  heapSort(lines)\n",
        "  files+=[file_path]\n",
        "  with open(file_path, \"w\") as f:\n",
        "        f.writelines(lines)\n",
        "\n",
        "def find_min(list_for_find_min):\n",
        "  min_index = 0\n",
        "  min = list_for_find_min[0]\n",
        "  for i in range (1,len(list_for_find_min)):\n",
        "    if min=='':\n",
        "      min = list_for_find_min[i]\n",
        "      min_index = i\n",
        "    if ((list_for_find_min[i]!='') and (list_for_find_min[i]<min)):\n",
        "      min = list_for_find_min[i]\n",
        "      min_index = i\n",
        "  \n",
        "  if min=='':\n",
        "    min_index = -1\n",
        "  return min_index\n",
        "\n",
        "def write_sorted(dir,files,to_file_path):\n",
        "  indexes = [0]*len(files)\n",
        "  opened_files = []\n",
        "  sorted = open(dir+to_file_path,'w')\n",
        "  for file in files:\n",
        "    opened_files+=[open(file)]\n",
        "\n",
        "  list_for_find_min=[]\n",
        "  for file in opened_files:\n",
        "    list_for_find_min+=[file.readline()]#считаем первые строки из всех файлов\n",
        "  min_index = 1\n",
        "  while min_index != -1:\n",
        "    min_index = find_min(list_for_find_min)\n",
        "    if min_index!=-1:\n",
        "      sorted.writelines(list_for_find_min[min_index])#пишем самую маленькую строку в фаил\n",
        "      list_for_find_min[min_index] = opened_files[min_index].readline()#сдвигаем строку только в том файле, откуда взяли строку\n",
        " \n",
        "\n",
        "  for file in opened_files:\n",
        "    file.close()\n",
        "  \n",
        "  sorted.close()\n",
        "\n",
        "def sort_big_file(dir,from_file_path,to_file_path,delete_temp_files_after_sorting):\n",
        "  count = 0\n",
        "  memused = 0\n",
        "  lines = []\n",
        "  files = []\n",
        "  next_file = dir+str(count)\n",
        "\n",
        "  with open(dir+from_file_path) as f:\n",
        "    for line in f:\n",
        "      if str(line)[-1]=='\\n':#возврат строки отрежем, а потом вернем, чтобы при сортировке он не мешал\n",
        "        line = str(line)[:-1]\n",
        "      else:\n",
        "        line = str(line)\n",
        "      memused+=len(line)\n",
        "      if memused>max_mem:#Если память закончилась, то записываем фаил и начинаем следующий.\n",
        "        sort_and_write_little_file(lines,next_file,files)\n",
        "        memused = len(line)\n",
        "        count+=1\n",
        "        lines = []\n",
        "        next_file = dir+str(count)\n",
        "      line = shell_sort(line)+'\\n'\n",
        "      lines +=[line]\n",
        "    sort_and_write_little_file(lines,next_file,files)#запишем остаток строк\n",
        "    if len(files)==1:#если фаил один, то не надо его записывать заново, просто переименуем\n",
        "      os.rename(dir+'0',dir+to_file_path)\n",
        "    else:\n",
        "      write_sorted(dir,files,to_file_path)\n",
        "      if delete_temp_files_after_sorting:\n",
        "        for file in files:\n",
        "          os.remove(file)\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTsV91rc3FO"
      },
      "source": [
        "Сортировка пирамидальная и шелла используются в разных случаях для ускорения работы алгоритма. Предполагается, что максимальная длина строки не слишком большая, и выгоднее по производительности будет использовать алгоритм шелла. Для файлов используется прирамидальная сортировка, т.к. она работает быстрее при большом объеме сортируемых данных.\n",
        "Алгоритмы взяты из открытых источников и доработаны под текущую задачу.\n",
        "\n",
        "Основная идея - чтобы не занимать память, будем делить наш большой фаил на части, чтобы размер одного файла не превышал заданный. \n",
        "Каждую считанную из исходного файла строку отсортируем алгоритмом Шелла.\n",
        "После этого сортируем весь массив отсортированных строк (общий размер которого не превышает заданного) и записываем в фаил.\n",
        "После того, как все строки из исходного файла отсортированы и записаны в маленькие файлы, начинаем писать в финальный фаил.\n",
        "Считываем первые строки из всех файлов, выбираем из них самыую маленькую, её записываем.\n",
        "Фаил, из которого взята самая маленькая строка, сдвигается на следующую строку, все остальные остаются на той же позиции, как и на прошлом шаге. Снова ищем самую маленькую строку. И т.д., пока все строки во всех файлах не закончатся.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VQju461B2e0"
      },
      "source": [
        "str_count = 200\n",
        "max_str_len = 30\n",
        "create_text_file(str_count,max_str_len,'/content/temp.txt')\n",
        "\n",
        "delete_temp_files_after_sorting = True\n",
        "max_mem = 50000\n",
        "sort_big_file('/content/','temp.txt','sorted.txt',delete_temp_files_after_sorting)"
      ],
      "execution_count": 143,
      "outputs": []
    }
  ]
}